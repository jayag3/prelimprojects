{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers here if you wish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable inline mode for matplotlib so that Jupyter displays graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset \n",
    "There is access to 303 patients data. The features are listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  \\\n",
       "0     63    1       typical     145   233    1        2    150      0   \n",
       "1     67    1  asymptomatic     160   286    0        2    108      1   \n",
       "2     67    1  asymptomatic     120   229    0        2    129      1   \n",
       "3     37    1    nonanginal     130   250    0        0    187      0   \n",
       "4     41    0    nontypical     130   204    0        2    172      0   \n",
       "..   ...  ...           ...     ...   ...  ...      ...    ...    ...   \n",
       "298   45    1       typical     110   264    0        0    132      0   \n",
       "299   68    1  asymptomatic     144   193    1        0    141      0   \n",
       "300   57    1  asymptomatic     130   131    0        0    115      1   \n",
       "301   57    0    nontypical     130   236    0        2    174      0   \n",
       "302   38    1    nonanginal     138   175    0        0    173      0   \n",
       "\n",
       "     Oldpeak  Slope   Ca        Thal Target  \n",
       "0        2.3      3  0.0       fixed     No  \n",
       "1        1.5      2  3.0      normal    Yes  \n",
       "2        2.6      2  2.0  reversable    Yes  \n",
       "3        3.5      3  0.0      normal     No  \n",
       "4        1.4      1  0.0      normal     No  \n",
       "..       ...    ...  ...         ...    ...  \n",
       "298      1.2      2  0.0  reversable    Yes  \n",
       "299      3.4      2  2.0  reversable    Yes  \n",
       "300      1.2      2  1.0  reversable    Yes  \n",
       "301      0.0      2  1.0      normal    Yes  \n",
       "302      0.0      1  NaN      normal     No  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "heart_df = pd.read_csv(\"Heart (5).csv\")\n",
    "heart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age:** The person’s age in years\n",
    "\n",
    "**Sex:** The person’s sex (1 = male, 0 = female)\n",
    "\n",
    "**ChestPain:** chest pain type\n",
    "\n",
    "* Value 0: asymptomatic\n",
    "* Value 1: atypical angina\n",
    "* Value 2: non-anginal pain\n",
    "* Value 3: typical angina\n",
    "\n",
    "**RestBP:** The person’s resting blood pressure (mm Hg on admission to the hospital)\n",
    "\n",
    "**Chol:** The person’s cholesterol measurement in mg/dl\n",
    "\n",
    "**Fbs:** The person’s fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "restecg: resting electrocardiographic results\n",
    "\n",
    "* Value 0: showing probable or definite left ventricular hypertrophy by Estes’ criteria\n",
    "* Value 1: normal\n",
    "* Value 2: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "\n",
    "**RestECG:** The person’s maximum heart rate achieved\n",
    "\n",
    "**MaxHR:** Exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "**Oldpeak:** ST depression induced by exercise relative to rest (‘ST’ relates to positions on the ECG plot. See more here)\n",
    "\n",
    "**Slope:** the slope of the peak exercise ST segment — 0: downsloping; 1: flat; 2: upsloping\n",
    "\n",
    "* 0: downsloping; \n",
    "* 1: flat; \n",
    "* 2: upsloping\n",
    "\n",
    "**Ca:** The number of major vessels (0–3)\n",
    "\n",
    "**Thal:** A blood disorder called thalassemia Value 0: NULL (dropped from the dataset previously\n",
    "\n",
    "* Value 1: fixed defect (no blood flow in some part of the heart)\n",
    "* Value 2: normal blood flow\n",
    "* Value 3: reversible defect (a blood flow is observed but it is not normal)\n",
    "\n",
    "**Target:** Heart disease (1 = no, 0= yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use **Suppert Vector Machine** to predict if the patients will have heart problems or not. The column \"Target\" in our datasets includes data about heart diseases. If the patient had heart disease have a 1 and if not a zero. \n",
    "\n",
    "Prepare data set for predicting heart disease (\"Target\" column) out of 3 features:\n",
    "\n",
    "* Age of the patient (Column **\"Age\"**)\n",
    "* Gender of the patient (male or female - Column **\"Sex\"**)\n",
    "* Cholestrol level of the patient (Column **\"Chol\"**) \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets to 1's and 0's\n",
    "heart_df['Target'] = np.where(heart_df['Target'] == 'No', 0, heart_df['Target'])\n",
    "\n",
    "heart_df['Target'] = np.where(heart_df['Target'] == 'Yes', 1, heart_df['Target'])\n",
    "\n",
    "\n",
    "#create train and test set\n",
    "train_set = heart_df.sample(frac = 0.8, random_state=102)\n",
    "test_set = heart_df.drop(train_set.index)\n",
    "\n",
    "#create the train values for x and y\n",
    "x_tra = np.array(pd.concat([train_set['Age'], train_set['Sex'], train_set['Chol']], axis = 1))\n",
    "\n",
    "y_tra = train_set['Target']\n",
    "y_tra = np.array(y_tra.astype('int'))\n",
    "\n",
    "\n",
    "#create the test values for x and y\n",
    "x_test = np.array(pd.concat([test_set['Age'], test_set['Sex'], test_set['Chol']], axis = 1))\n",
    "\n",
    "y_test = test_set['Target']\n",
    "y_test = np.array(y_test.astype('int'))\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "#create a classifier\n",
    "cls = svm.SVC()\n",
    "\n",
    "#train the model\n",
    "cls.fit(x_tra,y_tra)\n",
    "\n",
    "#predict the response\n",
    "pred = cls.predict(x_test)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Accuracy, Precision, Recall and F1 score of  **SVM** implementaion. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6557377049180327\n",
      "Precision:  0.6153846153846154\n",
      "Recall:  0.3333333333333333\n",
      "f1-score:  0.43243243243243246\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize the true positive and negative values\n",
    "true_pos = 0\n",
    "false_pos = 0\n",
    "true_neg = 0\n",
    "false_neg = 0\n",
    "\n",
    "#find the true negs, true positives, false positives, and false negs\n",
    "for i in range(0,len(y_test)):\n",
    "    if pred[i] == 0 and y_test[i] == 0:\n",
    "        true_neg+=1\n",
    "    if pred[i] ==0 and y_test[i] == 1:\n",
    "        false_neg+=1\n",
    "    if pred[i] == 1 and y_test[i] ==0:\n",
    "        false_pos+=1\n",
    "    if pred[i] ==1 and y_test[i] == 1:\n",
    "        true_pos+=1\n",
    "        \n",
    "#calculate accuracy\n",
    "accuracy = (true_pos+true_neg)/(true_pos + false_pos + false_neg + true_neg)\n",
    "\n",
    "print('Accuracy: ', accuracy)\n",
    "\n",
    "#calculate precision\n",
    "precision = true_pos/(true_pos+false_pos)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "\n",
    "#calculate recall\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "\n",
    "print('Recall: ', recall)\n",
    "\n",
    "#calculate f1\n",
    "f1 = 2 * (precision*recall)/(precision+recall)\n",
    "\n",
    "print('f1-score: ', f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Implement SVM from scratch using Hinge Loss function and Gradient Descent without libraries. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost is: 0.01 weights [0. 0. 0.]\n",
      "Epoch 1 Cost is: 0.009848557140686337 weights [2.66859504e-05 3.96694215e-07 1.20136364e-04]\n",
      "Epoch 2 Cost is: 0.009697144568430105 weights [5.33692322e-05 7.93348760e-07 2.40260714e-04]\n",
      "Epoch 3 Cost is: 0.0095457622771742 weights [8.00498457e-05 1.18996364e-06 3.60373051e-04]\n",
      "Epoch 4 Cost is: 0.009394410260862721 weights [1.06727791e-04 1.58653886e-06 4.80473378e-04]\n",
      "Epoch 5 Cost is: 0.009243088513440984 weights [1.33403069e-04 1.98307442e-06 6.00561694e-04]\n",
      "Epoch 6 Cost is: 0.009091797028855517 weights [1.60075679e-04 2.37957033e-06 7.20638001e-04]\n",
      "Epoch 7 Cost is: 0.00894053580105405 weights [1.86745622e-04 2.77602659e-06 8.40702301e-04]\n",
      "Epoch 8 Cost is: 0.008789304823985534 weights [2.13412898e-04 3.17244320e-06 9.60754595e-04]\n",
      "Epoch 9 Cost is: 0.008638104091600119 weights [2.40077507e-04 3.56882017e-06 1.08079488e-03]\n",
      "Epoch 10 Cost is: 0.008486933597849173 weights [2.66739449e-04 3.96515750e-06 1.20082317e-03]\n",
      "Epoch 11 Cost is: 0.008335793336685276 weights [2.93398726e-04 4.36145520e-06 1.32083945e-03]\n",
      "Epoch 12 Cost is: 0.008184683302062205 weights [3.20055336e-04 4.75771327e-06 1.44084373e-03]\n",
      "Epoch 13 Cost is: 0.00803360348793496 weights [3.46709281e-04 5.15393171e-06 1.56083601e-03]\n",
      "Epoch 14 Cost is: 0.007882553888259744 weights [3.73360561e-04 5.55011053e-06 1.68081629e-03]\n",
      "Epoch 15 Cost is: 0.007731534496993963 weights [4.00009175e-04 5.94624974e-06 1.80078457e-03]\n",
      "Epoch 16 Cost is: 0.007580545308096244 weights [4.26655125e-04 6.34234933e-06 1.92074085e-03]\n",
      "Epoch 17 Cost is: 0.007429586315526413 weights [4.53298410e-04 6.73840931e-06 2.04068514e-03]\n",
      "Epoch 18 Cost is: 0.007278657513245508 weights [4.79939030e-04 7.13442968e-06 2.16061744e-03]\n",
      "Epoch 19 Cost is: 0.0071277588952157675 weights [5.06576987e-04 7.53041045e-06 2.28053774e-03]\n",
      "Epoch 20 Cost is: 0.006977808481792453 weights [5.33212279e-04 7.92635163e-06 2.40044605e-03]\n",
      "Epoch 21 Cost is: 0.006835201181546418 weights [5.59353173e-04 8.32225321e-06 2.51697047e-03]\n",
      "Epoch 22 Cost is: 0.00669262240133436 weights [5.85491453e-04 8.71811520e-06 2.63348323e-03]\n",
      "Epoch 23 Cost is: 0.0065502536677138805 weights [6.11627118e-04 9.11393760e-06 2.74998435e-03]\n",
      "Epoch 24 Cost is: 0.006411432782354338 weights [6.37532898e-04 9.50558819e-06 2.86501514e-03]\n",
      "Epoch 25 Cost is: 0.006283438377351854 weights [6.62993938e-04 9.89306738e-06 2.97724103e-03]\n",
      "Epoch 26 Cost is: 0.0061711481594803885 weights [6.86944167e-04 1.02639789e-05 3.08131521e-03]\n",
      "Epoch 27 Cost is: 0.0060686258180417466 weights [7.10412663e-04 1.06307211e-05 3.18274675e-03]\n",
      "Epoch 28 Cost is: 0.005980894752596299 weights [7.32287903e-04 1.09767655e-05 3.27525079e-03]\n",
      "Epoch 29 Cost is: 0.0059023710987953885 weights [7.53243600e-04 1.13103785e-05 3.36282409e-03]\n",
      "Epoch 30 Cost is: 0.005838930456729253 weights [7.72821168e-04 1.16232971e-05 3.44324813e-03]\n",
      "Epoch 31 Cost is: 0.005786362954065815 weights [7.90710828e-04 1.19072587e-05 3.51549472e-03]\n",
      "Epoch 32 Cost is: 0.005743010181352768 weights [8.06970600e-04 1.21622663e-05 3.57979193e-03]\n",
      "Epoch 33 Cost is: 0.0057025375122682345 weights [8.22716349e-04 1.24131162e-05 3.64187197e-03]\n",
      "Epoch 34 Cost is: 0.005664720043745308 weights [8.38237383e-04 1.26598088e-05 3.70284662e-03]\n",
      "Epoch 35 Cost is: 0.0056326188041835885 weights [8.52847774e-04 1.28940800e-05 3.75950940e-03]\n",
      "Epoch 36 Cost is: 0.0056066565201700605 weights [8.65750093e-04 1.30994022e-05 3.80880287e-03]\n",
      "Epoch 37 Cost is: 0.005582183558491527 weights [8.78651121e-04 1.33047038e-05 3.85809141e-03]\n",
      "Epoch 38 Cost is: 0.005561615390736376 weights [8.90348380e-04 1.34934560e-05 3.90225519e-03]\n",
      "Epoch 39 Cost is: 0.005541985211465678 weights [9.01788271e-04 1.36821893e-05 3.94540628e-03]\n",
      "Epoch 40 Cost is: 0.005524941393590905 weights [9.12590654e-04 1.38626392e-05 3.98554893e-03]\n",
      "Epoch 41 Cost is: 0.0055084997609025875 weights [9.23115097e-04 1.40389389e-05 4.02470823e-03]\n",
      "Epoch 42 Cost is: 0.005492272545794603 weights [9.33638488e-04 1.42152210e-05 4.06386361e-03]\n",
      "Epoch 43 Cost is: 0.005477094081387673 weights [9.43921157e-04 1.43873532e-05 4.10204813e-03]\n",
      "Epoch 44 Cost is: 0.005464092493324777 weights [9.53483790e-04 1.45470715e-05 4.13736107e-03]\n",
      "Epoch 45 Cost is: 0.005453155586425547 weights [9.62322326e-04 1.46985093e-05 4.16983163e-03]\n",
      "Epoch 46 Cost is: 0.005444039658911474 weights [9.70502953e-04 1.48416676e-05 4.19946836e-03]\n",
      "Epoch 47 Cost is: 0.005435884703078915 weights [9.78286068e-04 1.49806793e-05 4.22721784e-03]\n",
      "Epoch 48 Cost is: 0.005428122287784377 weights [9.85828735e-04 1.51155448e-05 4.25403892e-03]\n",
      "Epoch 49 Cost is: 0.0054203614248952755 weights [9.93370648e-04 1.52503969e-05 4.28085732e-03]\n",
      "Epoch 50 Cost is: 0.00541262950847074 weights [1.00091181e-03 1.53852355e-05 4.30767303e-03]\n",
      "Epoch 51 Cost is: 0.005405689276267531 weights [1.00828692e-03 1.55159284e-05 4.33356458e-03]\n",
      "Epoch 52 Cost is: 0.005399479125743624 weights [1.01517783e-03 1.56383438e-05 4.35765188e-03]\n",
      "Epoch 53 Cost is: 0.0053940957244281405 weights [1.02160111e-03 1.57524824e-05 4.37994752e-03]\n",
      "Epoch 54 Cost is: 0.005389023672601331 weights [1.02802374e-03 1.58666096e-05 4.40224093e-03]\n",
      "Epoch 55 Cost is: 0.005384991871857016 weights [1.03373499e-03 1.59683288e-05 4.42187509e-03]\n",
      "Epoch 56 Cost is: 0.005381177419757441 weights [1.03918120e-03 1.60659055e-05 4.44063125e-03]\n",
      "Epoch 57 Cost is: 0.0053773637305101415 weights [1.04462687e-03 1.61634724e-05 4.45938553e-03]\n",
      "Epoch 58 Cost is: 0.005373715483644365 weights [1.05007199e-03 1.62610296e-05 4.47813794e-03]\n",
      "Epoch 59 Cost is: 0.005370247094223029 weights [1.05530170e-03 1.63544449e-05 4.49601244e-03]\n",
      "Epoch 60 Cost is: 0.005366779398444894 weights [1.06053088e-03 1.64478507e-05 4.51388516e-03]\n",
      "Epoch 61 Cost is: 0.005363440552430333 weights [1.06575953e-03 1.65412473e-05 4.53175608e-03]\n",
      "Epoch 62 Cost is: 0.005360352357710633 weights [1.07073560e-03 1.66305022e-05 4.54876985e-03]\n",
      "Epoch 63 Cost is: 0.0053575171986919926 weights [1.07546324e-03 1.67156161e-05 4.56493067e-03]\n",
      "Epoch 64 Cost is: 0.005354767383462862 weights [1.08019040e-03 1.68007213e-05 4.58108988e-03]\n",
      "Epoch 65 Cost is: 0.005352291146786449 weights [1.08469395e-03 1.68816859e-05 4.59639624e-03]\n",
      "Epoch 66 Cost is: 0.005350119462664369 weights [1.08895325e-03 1.69585101e-05 4.61085808e-03]\n",
      "Epoch 67 Cost is: 0.005348113612718922 weights [1.09296006e-03 1.70311944e-05 4.62447964e-03]\n",
      "Epoch 68 Cost is: 0.005346337323641446 weights [1.09675159e-03 1.70997393e-05 4.63725686e-03]\n",
      "Epoch 69 Cost is: 0.005344656538301999 weights [1.10054274e-03 1.71682772e-05 4.65003281e-03]\n",
      "Epoch 70 Cost is: 0.005343104360722117 weights [1.10411451e-03 1.72326761e-05 4.66196863e-03]\n",
      "Epoch 71 Cost is: 0.0053415524935622296 weights [1.10768591e-03 1.72970685e-05 4.67390326e-03]\n",
      "Epoch 72 Cost is: 0.005340000936760255 weights [1.11125696e-03 1.73614545e-05 4.68583670e-03]\n",
      "Epoch 73 Cost is: 0.0053384496902541285 weights [1.11482766e-03 1.74258341e-05 4.69776894e-03]\n",
      "Epoch 74 Cost is: 0.005336898753981786 weights [1.11839799e-03 1.74902072e-05 4.70969999e-03]\n",
      "Epoch 75 Cost is: 0.00533536638912705 weights [1.12196797e-03 1.75545739e-05 4.72162985e-03]\n",
      "Epoch 76 Cost is: 0.005334020729525843 weights [1.12533098e-03 1.76148019e-05 4.73273206e-03]\n",
      "Epoch 77 Cost is: 0.005332675339043098 weights [1.12869365e-03 1.76750239e-05 4.74383317e-03]\n",
      "Epoch 78 Cost is: 0.005331330217624997 weights [1.13205599e-03 1.77352399e-05 4.75493317e-03]\n",
      "Epoch 79 Cost is: 0.005329985365217729 weights [1.13541799e-03 1.77954498e-05 4.76603205e-03]\n",
      "Epoch 80 Cost is: 0.005328640781767493 weights [1.13877966e-03 1.78556537e-05 4.77712983e-03]\n",
      "Epoch 81 Cost is: 0.005327371310890577 weights [1.14214098e-03 1.79158516e-05 4.78822650e-03]\n",
      "Epoch 82 Cost is: 0.005326215977554843 weights [1.14522099e-03 1.79719113e-05 4.79852453e-03]\n",
      "Epoch 83 Cost is: 0.005325060875274222 weights [1.14830068e-03 1.80279653e-05 4.80882154e-03]\n",
      "Epoch 84 Cost is: 0.005323907861769985 weights [1.15138006e-03 1.80840138e-05 4.81911752e-03]\n",
      "Epoch 85 Cost is: 0.0053229250685857005 weights [1.15427732e-03 1.81359244e-05 4.82859842e-03]\n",
      "Epoch 86 Cost is: 0.005321942471950225 weights [1.15717429e-03 1.81878298e-05 4.83807837e-03]\n",
      "Epoch 87 Cost is: 0.005320978133094795 weights [1.16007097e-03 1.82397300e-05 4.84755737e-03]\n",
      "Epoch 88 Cost is: 0.005320152495759143 weights [1.16282273e-03 1.82874928e-05 4.85621724e-03]\n",
      "Epoch 89 Cost is: 0.0053193270235427 weights [1.16557422e-03 1.83352509e-05 4.86487625e-03]\n",
      "Epoch 90 Cost is: 0.0053185017164124465 weights [1.16832543e-03 1.83830041e-05 4.87353439e-03]\n",
      "Epoch 91 Cost is: 0.005317676574335366 weights [1.17107636e-03 1.84307526e-05 4.88219166e-03]\n",
      "Epoch 92 Cost is: 0.005316851597278449 weights [1.17382703e-03 1.84784963e-05 4.89084807e-03]\n",
      "Epoch 93 Cost is: 0.005316026785208694 weights [1.17657741e-03 1.85262352e-05 4.89950362e-03]\n",
      "Epoch 94 Cost is: 0.005315202138093105 weights [1.17932752e-03 1.85739694e-05 4.90815829e-03]\n",
      "Epoch 95 Cost is: 0.0053143776558986925 weights [1.18207736e-03 1.86216988e-05 4.91681211e-03]\n",
      "Epoch 96 Cost is: 0.005313553338592474 weights [1.18482692e-03 1.86694234e-05 4.92546505e-03]\n",
      "Epoch 97 Cost is: 0.005312729186141473 weights [1.18757621e-03 1.87171432e-05 4.93411713e-03]\n",
      "Epoch 98 Cost is: 0.0053119051985127215 weights [1.19032522e-03 1.87648583e-05 4.94276835e-03]\n",
      "Epoch 99 Cost is: 0.005311081375673256 weights [1.19307395e-03 1.88125685e-05 4.95141870e-03]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75        37\n",
      "           1       0.62      0.33      0.43        24\n",
      "\n",
      "    accuracy                           0.66        61\n",
      "   macro avg       0.64      0.60      0.59        61\n",
      "weighted avg       0.65      0.66      0.63        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(X, y, W, regularization_factor):\n",
    "    '''This function calculate the hinge loss. Primal Problem in SVM'''\n",
    "    n = X.shape[0]\n",
    "    distances = 1 - y * (np.dot(X, W))\n",
    "    \n",
    "    # This is our max(0, distance). \n",
    "    distances[distances < 0] = 0 \n",
    "    \n",
    "    hinge_loss = regularization_factor * (np.sum(distances) / n)\n",
    "    # This divide by 2 is not important. You can skip doing it \n",
    "    # because we want only to check if this cost is going down or not. \n",
    "    return (1 / 2 * np.dot(W, W) + hinge_loss)\n",
    "\n",
    "def calculate_gradient(X, y, W, regularization_factor):\n",
    "      \n",
    "    if type(y) == np.float64:\n",
    "        y = np.array([y])\n",
    "        X = np.array([X])\n",
    "        \n",
    "    distance = 1 - (y * np.dot(X, W))\n",
    "    \n",
    "    dw = np.zeros(len(W))\n",
    "    \n",
    "    for ind, d in enumerate(distance):\n",
    "        \n",
    "        if (d < 0):\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_factor * y[ind] * X[ind])\n",
    "            \n",
    "            \n",
    "        dw += di\n",
    "    \n",
    "    dw = dw/len(y)  # average\n",
    "    \n",
    "    return dw\n",
    "\n",
    "\n",
    "weights = np.zeros(3)\n",
    "\n",
    "\n",
    "# Now we optimize it using Gradient Descent. \n",
    "num_iterations = 100\n",
    "learnin_rate = 0.0001\n",
    "\n",
    "regularization = 0.01\n",
    "\n",
    "cost_list = []\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "    \n",
    "    cost = compute_cost(x_tra, y_tra, weights, regularization)\n",
    "    \n",
    "    print(\"Epoch\", i, \"Cost is:\", cost, \"weights\", weights)\n",
    "    \n",
    "    cost_list.append(cost)\n",
    "    \n",
    "    grad = calculate_gradient(x_tra, y_tra, weights, regularization)\n",
    "    \n",
    "    weights = weights - learnin_rate * grad\n",
    "    \n",
    "\n",
    "#visualize costs\n",
    "plt.plot(np.arange(num_iterations), cost_list)\n",
    "plt.show()\n",
    "\n",
    "y_predict_2 = np.where(np.dot(x_test, weights)<0, -1, 1)\n",
    "\n",
    "y_predict_2\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "class_report = classification_report(y_test,pred)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare SVM results with Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM class report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        37\n",
      "           1       0.79      0.46      0.58        24\n",
      "\n",
      "    accuracy                           0.74        61\n",
      "   macro avg       0.75      0.69      0.69        61\n",
      "weighted avg       0.75      0.74      0.72        61\n",
      "\n",
      "\n",
      "\n",
      "Log class report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.71        37\n",
      "           1       0.57      0.67      0.62        24\n",
      "\n",
      "    accuracy                           0.67        61\n",
      "   macro avg       0.66      0.67      0.66        61\n",
      "weighted avg       0.68      0.67      0.68        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM results \n",
    "from sklearn.metrics import *\n",
    "\n",
    "class_report = classification_report(y_test,pred)\n",
    "print('SVM class report\\n')\n",
    "print(class_report)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#Logistic Regression results\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_tra,y_tra)\n",
    "y_pred=logreg.predict(x_test)\n",
    "\n",
    "\n",
    "class_report_log = classification_report(y_test,y_pred)\n",
    "\n",
    "print('Log class report\\n')\n",
    "print(class_report_log)\n",
    "\n",
    "#SVM more accurate than log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a kernel function to improve SVM performance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        37\n",
      "           1       0.79      0.46      0.58        24\n",
      "\n",
      "    accuracy                           0.74        61\n",
      "   macro avg       0.75      0.69      0.69        61\n",
      "weighted avg       0.75      0.74      0.72        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "\n",
    "#create a classifier\n",
    "cls = svm.SVC(kernel = 'poly', degree = 5)\n",
    "\n",
    "#train the model\n",
    "cls.fit(x_tra,y_tra)\n",
    "\n",
    "#predict the response\n",
    "pred = cls.predict(x_test)\n",
    "\n",
    "pred\n",
    "\n",
    "\n",
    "class_report = classification_report(y_test,pred, zero_division=0)\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
